{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: Movie recommendation as an example**<br>\n",
    "\n",
    "Given a $n \\times m$ matrix, $Y$, containing $n$ users and $m$ movies, recommend movies to users that have not been seen by each of them.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**K-Nearest Neighbours (KNN)**\n",
    "\n",
    "*How many similar (nearest) neighbours do we want to use as information to recommend a movie to a given user?*\n",
    "\n",
    "$\\hat Y_{ij} = \\frac{\\sum_{b \\in KNN(i, j)} Y_{bi}}{K}$\n",
    "\n",
    "where\n",
    "\n",
    "- $b$ represents each neighbour/user\n",
    "- $K$ represents the number of nearest neighbours selected\n",
    "- $Y_{bi}$ represents the score given by each of the nearest neighbour\n",
    "- $\\hat Y_{ij}$ represents the estimated score from $K$ nearest neighbours to a given user\n",
    "\n",
    "*How do we define similarity distance between two users (vectors)?* i.e. $sim(a,b)$ as a similarity measure between users $a$ and $b \\in KNN(a)$\n",
    "\n",
    "- Cosine similarity $\\cos \\theta = \\frac{x_a \\cdot x_b}{\\Vert x_a \\Vert \\Vert x_b \\Vert}$\n",
    "- Euclidean distance $\\Vert x_a - x_b \\Vert$, etc.\n",
    "- Using algorithms, like *collaborative filtering*, which frees us from the need to define a good similarity measure\n",
    "\n",
    "****\n",
    "\n",
    "**Collaborative Filtering**\n",
    "\n",
    "Given a $n \\times m$ matrix, $Y$, which is generally a sparse matrix, output a matrix $X$ in the same dimensions that has all non-zero entries with estimated scores.\n",
    "\n",
    "An empirical risk function can be defined as follows:\n",
    "\n",
    "$J(X) = \\sum_{(i, j) \\in D} \\frac{(Y_{ij} - X_{ij})^2}{2} + \\frac{\\lambda}{2} \\cdot \\sum_{(i, j)} X_{ij}^2$\n",
    "\n",
    "where\n",
    "\n",
    "- $D$ are all $i, j$ entries which are non-zero in the original matrix, $Y$\n",
    "- The regularization term goes over all pairs in the matrix, $Y$\n",
    "\n",
    "\n",
    "The risk function, when setting its derivative to zero, ends up with an unsatisfactory and trivial solution of $X$.\n",
    "\n",
    "Using the collaborative filtering approach, we make a strong assumption that $X$ has low rank, i.e. there exist linear combinations in which we can now use matrix factorizations, such that $X$ can be decomposed into $X = U \\cdot V^T$, where $U$ is a $n \\times d$ matrix and $V^T$ is a $d \\times m$ matrix, with $d$ as the rank of the matrix $X$.\n",
    "\n",
    "Each row of $U$ represents a user's rating tendency and each column of $V^T$ represents the information on a movie.\n",
    "\n",
    "$\\therefore X_{ij} = U_i \\cdot V_j$ in a rank 1 matrix, $X$\n",
    "\n",
    "$J(X) = J(U, V) = \\sum_{(i, j) \\in D} \\frac{(Y_{ij} - U_i \\cdot V_j)^2}{2} + \\frac{\\lambda}{2} \\sum_{i=1}^{n} U_i^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{m} V_j^2$\n",
    "\n",
    "\n",
    "*Example*, given $Y = \\begin{bmatrix} 5 & ? & 7 \\\\ 1 & 2 & ? \\end{bmatrix}$, estimate $U = \\begin{bmatrix} U_1 \\\\ U_2 \\end{bmatrix}$ and $V = \\begin{bmatrix} V_1 \\\\ V_2 \\\\ V_3 \\end{bmatrix}$, assuming that $Y$ is a rank 1 matrix.\n",
    "\n",
    "1. Initialize $V = \\begin{bmatrix} 2 \\\\ 7 \\\\ 8 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "2. Compute $U \\cdot V^T$\n",
    "\n",
    "    $U \\cdot V^T = \\begin{bmatrix} U_1 \\\\ U_2 \\end{bmatrix} \\begin{bmatrix} 2 & 7 & 8 \\end{bmatrix} = \\begin{bmatrix} 2U_1 & 7U_1 & 8U_1 \\\\ 2U_2 & 7U_2 & 8U_2 \\end{bmatrix}$\n",
    "    \n",
    "\n",
    "3. Solve for $U_1, U_2$ using known entries in $Y$, by rewriting the loss function for each user, $i$\n",
    "\n",
    "    $\\nabla_U [ \\frac{(5-2U_1)^2}{2} + \\frac{(7-8U_1)^2}{2} + \\frac{\\lambda}{2} U_1^2 ]$\n",
    "    \n",
    "    $U_1 = \\frac{66}{\\lambda + 68}$\n",
    "    \n",
    "    $U_2 = \\frac{16}{\\lambda + 53}$\n",
    "    \n",
    "    Solve for both by selecting a fixed $\\lambda$, say $\\lambda = 1$\n",
    "    \n",
    "\n",
    "4. Given solved values of $U_1, U_2$, now solve for $V$\n",
    "\n",
    "    $\\begin{bmatrix} \\frac{66}{69} \\\\ \\frac{16}{54} \\end{bmatrix} \\begin{bmatrix} V_1 & V_2 & V_3 \\end{bmatrix}$\n",
    "\n",
    "    \n",
    "5. Repeat process until covergence of values: This only guarantees local covergence and this depends on initialization values. Repeat the process with different initializations and check against validation sets\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
