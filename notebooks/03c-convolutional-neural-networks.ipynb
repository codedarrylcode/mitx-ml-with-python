{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gentle introduction to CNNs**<br>\n",
    "\n",
    "The key components of a CNN are the following:\n",
    "\n",
    "1. **Patch filtering**\n",
    "\n",
    "    Takes a small patch of an image as the input, a feature of the image that we would like to capture, and learn the weights to recognize a given patch.\n",
    "    \n",
    "    If the input image has a feature similar to the patch, then the $ReLU$ activation function would generate a large response.\n",
    "    \n",
    "    We break up the image into patches of the same size and pass it through patch weights and transform it into a feature map that indicates if the activation function generates a large response, i.e. How much of the target feature exists in this patch?\n",
    "    \n",
    "    <img alt=\"Patch Filter\" src=\"assets/patch_filter.png\" width=\"400\">\n",
    "    \n",
    "    <img alt=\"Convolution\" src=\"assets/convolution_to_feature_map.png\" width=\"400\">\n",
    "\n",
    "    \n",
    "    \n",
    "2. **Pooling**\n",
    "\n",
    "    Given that we just want to know if the feature exists and not where it is, then we run *pooling* to find the maximum value of a patch in the *feature map* from (1). These maximum values get transformed into a *pooled map* which will be in smaller dimension than the feature map.\n",
    "    \n",
    "    <img alt=\"Pooling\" src=\"assets/pooling.png\" width=\"400\">\n",
    "\n",
    "    \n",
    "****\n",
    "\n",
    "**Convolution operation to create a feature map**\n",
    "\n",
    "Here, we formally define the convolution as an operation between two functions $f$ and $g$:\n",
    "\n",
    "$(f * g)(t) \\equiv \\int _{-\\infty }^{+\\infty } f(\\tau )g(t-\\tau )d\\tau$\n",
    "\n",
    "where $f$ is the image, $g$ is the patch filter, $\\tau$ is the dummy variable for integration and $t$ is the parameter of interest. Intuitively, convolution *blends* the two functions by expressing the amount of overlap. Suppose if an image patch, the input signal $f$, contains a feature in the filter patch $g$ then we expect the convolutional output to generate a large response, i.e. the area under the curve between the product of these two functions (the overlap).\n",
    "\n",
    "Suppose $f$ is a 2D discrete signal and we have a filter $g'$ of the following:\n",
    "\n",
    "$f = \\begin{bmatrix}  1 &  2 &  1 \\\\ 2 &  1 &  1 \\\\ 1 &  1 &  1 \\end{bmatrix}$\n",
    "\n",
    "$g' = \\begin{bmatrix}  1 &  0.5 \\\\ 0.5 &  1 \\end{bmatrix}$\n",
    "\n",
    "We move the filter around $f$ and multiply element-wise, resulting in a convolutional output of the following:\n",
    "\n",
    "$C = \\begin{bmatrix}  4 &  4 \\\\ 4 &  3 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "**Pooling operation to create a pooled map**\n",
    "\n",
    "Here we formally define pooling as an operation:\n",
    "\n",
    "$\\text {Pool}(\\text {ReLU}(\\text {Conv}(I)))$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\text {ReLU}(x) = \\text {max}(0, x)$\n",
    "- $\\text {Pool} = \\text{max} (\\text{ReLU}(x))$\n",
    "\n",
    "\n",
    "Given an image $I$, filter weights $F$, the following is a an example of how we would arrive at an output:\n",
    "\n",
    "$I = \\begin{bmatrix}  1 &  0 &  2 \\\\ 3 &  1 &  0 \\\\ 0 &  0 &  4 \\end{bmatrix}$\n",
    "\n",
    "$F = \\begin{bmatrix}  1 &  0 \\\\ 0 &  1 \\end{bmatrix}$\n",
    "\n",
    "$\\text {Conv}(I) = \\begin{bmatrix}  1 &  0 &  2 \\\\ 3 &  1 &  0 \\\\ 0 &  0 &  4 \\end{bmatrix}. \\begin{bmatrix}  1 &  0 \\\\ 0 &  1 \\end{bmatrix}$\n",
    "\n",
    "$\\text {Conv}(I) = \\begin{bmatrix}  2 &  0 \\\\ 3 &  5 \\end{bmatrix}$\n",
    "\n",
    "$\\text {ReLU}(\\text {Conv}(I)) = \\text {ReLU}(\\begin{bmatrix}  2 &  0 \\\\ 3 &  5 \\end{bmatrix})$\n",
    "\n",
    "$\\text {ReLU}(\\text {Conv}(I)) = \\begin{bmatrix}  2 &  0 \\\\ 3 &  5 \\end{bmatrix}$\n",
    "\n",
    "$\\text {Pool}(\\text {ReLU}(\\text {Conv}(I))) = \\text {Pool}(\\begin{bmatrix}  2 &  0 \\\\ 3 &  5 \\end{bmatrix})$\n",
    "\n",
    "$\\text {Pool}(\\text {ReLU}(\\text {Conv}(I))) = 5$\n",
    "\n",
    "****\n",
    "\n",
    "**Constructing a CNN, in reality**\n",
    "\n",
    "1. Map an input into multiple feature maps, based on the number of features that we would like to capture\n",
    "2. Run a pooling layer to extract the maximum value of each feature map\n",
    "3. Create another convolutional layer to extract a combination of these features\n",
    "4. Another pooling layer to extract the maximum value of these combinations\n",
    "5. Finally, an output classification\n",
    "\n",
    "<img alt=\"CNN Construction\" src=\"assets/cnn_construction.png\" width=\"600\">\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code\n",
    "A `minimal, reproducible example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:31:28.379141Z",
     "start_time": "2021-12-07T10:31:25.173409Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
